

## _传统ML_

keras, sklearn


</br>


## _Pytorch & Tensorflow_


> Tensorflow 就别来了，大坑货，官方文档中文的不维护就算了，版本低了几个版本；还只支持到 CUDA 11.2，用 torch 的还得降低 cuda 版本。文档也是乱糟糟的。

[tensorflow 版本与依赖对应](https://tensorflow.google.cn/install/source#gpu)，用于搭建环境




</br>

## _JAX_

Google的JAX是一个用于高性能机器学习的Python库。它的主要作用是提供了一种用于编写、优化和加速数值代码的框架。具体而言，JAX具有以下几个特点和作用：

1. 自动微分：JAX提供了自动微分的功能，使得能够轻松地计算函数的一阶和高阶导数。这对于训练神经网络和优化算法非常有用。

2. XLA编译器：JAX使用XLA（加速线性代数）编译器来加速计算，将代码转换为高效的机器码。这样可以显著提高计算性能。

3. NumPy兼容性：JAX与NumPy兼容，因此可以无缝地与现有的NumPy代码进行交互。这使得迁移和调试现有的代码变得更加容易。

4. 随机数生成器：JAX提供了高性能的随机数生成器，可以用于生成随机数、初始化模型参数等。

5. 分布式计算：JAX支持分布式计算，可以在多个设备和多个机器上进行并行计算，加速训练过程。

总的来说，JAX为机器学习开发者提供了一个高性能、易于使用的工具，使他们能够更快地开发和训练复杂的模型。


> 那我为什么不用 pytorch呢？google 为什么要重复造轮子？

选择使用JAX还是PyTorch取决于个人的需求和偏好。虽然两者都是用于机器学习的框架，但它们在一些方面有所不同。

1. 性能：JAX在性能方面具有优势，特别是在使用XLA编译器进行加速时。JAX的编译和执行速度可能比PyTorch更快，尤其是在大规模计算和分布式计算方面。

2. 自动微分：JAX的自动微分功能更加灵活和强大。它支持高阶导数的计算，并且可以轻松地将自定义的数学函数转换为可微分的操作。这对于一些需要高阶导数的算法和研究非常有用。

3. NumPy兼容性：JAX与NumPy兼容，这使得迁移和调试现有的NumPy代码变得更加容易。如果你已经熟悉NumPy，并且希望无缝地将现有的NumPy代码转换为可在JAX中运行的代码，那么JAX可能是一个更好的选择。

至于为什么Google要开发JAX，这可能有几个原因：

1. 性能需求：Google可能有一些对高性能计算的特定需求，而JAX可以满足这些需求。通过使用XLA编译器和其他优化技术，JAX可以提供更高效的计算能力。

2. 研究和开发：Google可能希望在机器学习领域进行研究和开发，并且需要一个灵活、高性能的框架来支持他们的工作。JAX可能是为了满足这些需求而开发的。

总的来说，JAX和PyTorch都是强大的机器学习框架，选择使用哪个取决于个人的需求和偏好。


--------------

参考资料：
- chatgpt

