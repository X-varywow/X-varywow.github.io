
启发式算法 Heuristic Algorithm

一种基于经验的算法，用来优化整个探索的过程。

- 模拟退火算法
- 遗传算法（不断删除指标低的）
- 蚁群算法
- 差分进化算法
- 鱼群算法
- 免疫优化算法
- 粒子群优化算法(Particle Swarm Optimization, PSO) 




```python
!pip install scikit-opt
```


</br>

## _模拟退火_

Simulated Annealing

物理上的退火：一般是材料加工过程中，加热到一定温度后缓慢冷却的过程，可以改善材料的物理性质和化学性质。

将能量视为目标函数，将能量降低到最小；

只是照着一个方向求解方程的一个近似解？


-------------

demo: 求解一个一元函数 x\*\*2 + 10\*math.sin(x) 的最小值

```python
import random
import math

# 目标函数，这里以一个简单的二次函数为例
def objective_function(x):
    return abs(x**2 + 10*math.sin(x))

# 冷却计划，定义温度下降的速度
def cooling_schedule(temperature, step, min_temperature = 1e-10):
    res = temperature * (1 - 0.01**step)
    res = max(res, min_temperature)
    return res

# 接受新解的概率函数
def acceptance_probability(old_energy, new_energy, temperature):
    if new_energy < old_energy:
        return 1.0
    else:
        return math.exp((old_energy - new_energy) / temperature)

# 模拟退火算法
def simulated_annealing(temperature, cooling_rate, steps):
    # 随机初始化当前解
    current_solution = random.uniform(-100, 100)
    current_energy = objective_function(current_solution)

    best_solution = current_solution
    best_energy = current_energy
    
    for step in range(steps):
        
        # 生成新的解
        new_solution = current_solution + random.uniform(-1, 1)
        new_energy = objective_function(new_solution)

        # 计算能量差
        energy_difference = new_energy - current_energy
        
        # 如果新解更优或根据温度接受更差解
        if energy_difference < 0 or random.uniform(0, 1) < math.exp(-energy_difference / temperature):
            current_solution = new_solution
            current_energy = new_energy

            if current_energy < best_energy:
                best_solution = current_solution
                best_energy = current_energy

        # 降低温度
        temperature = cooling_schedule(temperature, step)
    return best_solution, best_energy

# 参数设置
initial_temperature = 1000  # 初始温度
cooling_rate = 0.99  # 冷却速率
steps = 10000  # 迭代步数

# 运行模拟退火算法
for i in range(10):
    best_solution, best_energy = simulated_annealing(initial_temperature, cooling_rate, steps)
    print(f"Best solution: {best_solution}, Energy: {best_energy}")

# 终止条件可根据迭代轮次，温度阈值设定
```

这里 math.exp((old_energy - new_energy) / temperature) 是一个物理性质。

接受新解的概率计算公式基于玻尔兹曼分布，即使新解比当前解能量更高，也可能被接受。

玻尔兹曼分布是状态能量与系统温度的概率分布函数，给出了粒子处于特定状态下的概率。

$$p_i = \frac{1}{Q}e^{-\epsilon_i/(kT)} = \frac{e^{-\epsilon_i/(kT)}}{\sum_{j-1}^M e^{-\epsilon_j/(kT)}}$$

玻尔兹曼分布是使熵最大化的分布。

$$H(p_1, p_2, ..., p_M) = -\sum_{i=1}^Mp_ilog_2p_i$$




</br>

## _差分进化_

STEP1：定义约束优化问题
```python
'''
min f(x1, x2, x3) = x1^2 + x2^2 + x3^2
s.t.
    x1*x2 >= 1
    x1*x2 <= 5
    x2 + x3 = 1
    0 <= x1, x2, x3 <= 5
'''


def obj_func(p):
    x1, x2, x3 = p
    return x1 ** 2 + x2 ** 2 + x3 ** 2


constraint_eq = [
    lambda x: 1 - x[1] - x[2]
]

constraint_ueq = [
    lambda x: 1 - x[0] * x[1],
    lambda x: x[0] * x[1] - 5
]
```

STEP2：差分进化
```python
from sko.DE import DE

de = DE(func=obj_func, n_dim=3, size_pop=50, max_iter=800, lb=[0, 0, 0], ub=[5, 5, 5],
        constraint_eq=constraint_eq, constraint_ueq=constraint_ueq)

best_x, best_y = de.run()
print('best_x:', best_x, '\n', 'best_y:', best_y)
```






</br>

## _遗传算法_

(Genetic Algorithm, GA) 是一种模拟生物进化过程的搜索启发式算法


```python
import random

# 定义目标函数
def fitness(x):
    return x * x

# 生成初始种群
def create_population(size, min_value, max_value):
    return [random.randint(min_value, max_value) for _ in range(size)]

# 选择操作
def select(population):
    return sorted(population, key=fitness, reverse=True)[:2]

# 交叉操作
def crossover(parent1, parent2):
    return (parent1 + parent2) // 2

# 变异操作
def mutate(individual, mutation_rate, min_value, max_value):
    if random.random() < mutation_rate:
        return random.randint(min_value, max_value)
    return individual

# 遗传算法主函数
def genetic_algorithm(population_size, generations, min_value, max_value, mutation_rate):
    population = create_population(population_size, min_value, max_value)

    for _ in range(generations):
        parent1, parent2 = select(population)
        offspring = crossover(parent1, parent2)

        # 变异
        offspring = mutate(offspring, mutation_rate, min_value, max_value)
        
        # 更新种群
        population[random.randint(0, population_size - 1)] = offspring

    # 返回最优解
    return max(population, key=fitness)

# 设置参数
population_size = 20
generations = 50
min_value = 0
max_value = 10
mutation_rate = 0.1

# 运行遗传算法
best_solution = genetic_algorithm(population_size, generations, min_value, max_value, mutation_rate)
print(f"最优解: {best_solution}, 函数值: {fitness(best_solution)}")
```


</br>

## _粒子群优化_

源于鸟群觅食行为，通过鸟群分散和共享群体信息找到最优解


demo1. 调包

```python
from sko.PSO import PSO
import matplotlib.pyplot as plt

def demo_func(x):
    x1, x2, x3 = x
    return x1 ** 2 + (x2 - 0.05) ** 2 + x3 ** 2


pso = PSO(func=demo_func, n_dim=3, pop=40, max_iter=150, lb=[0, -1, 0.5], ub=[1, 1, 1], w=0.8, c1=0.5, c2=0.5)
pso.run()
print('best_x is ', pso.gbest_x, 'best_y is', pso.gbest_y)


plt.plot(pso.gbest_y_hist)
plt.show()
```


demo2. 手动实现

参考：https://zhuanlan.zhihu.com/p/564819718

```python
# 初始化粒子

for i in range(iters):
    # 计算局部粒子最优
    # 计算整体粒子最优
    # 粒子速度、位置进化
    #     1. 先计算速度，依赖个体记忆，全局记忆
    #     2. 速度出来后调整位置
```

求函数f(x,y) = 3*cos(x * y) + x + y**2的最小值，

其中-5 <= x <= 5, -5 <= y <= 5


```python
import random
import numpy as np
from math import cos

x_left = -5
x_right = 5

# 个体学习因子；全体学习因子
c1, c2 = 0.5, 0.5

# 定义目标函数
def objective_function(x):
    x1, x2 = x
    return 3*cos(x1*x2) + x1 + x2**2

# 初始化粒子群
def initialize_particles(particle_count, dimension):
    particles = []
    for _ in range(particle_count):
        particle = {
            'position': np.random.uniform(x_left, x_right, dimension),
            'velocity': np.random.uniform(-1, 1, dimension),
            'best_position': np.random.uniform(x_left, x_right, dimension),
            'best_value': float('inf')
        }
        particles.append(particle)
    return particles

# 更新粒子
def update_particles(particles, global_best_position):
    for particle in particles:
        for i in range(len(particle['position'])):
            r1, r2 = random.random(), random.random()
            cognitive_component = c1 * r1 * (particle['best_position'][i] - particle['position'][i])   # 粒子对个体最佳位置吸引力
            social_component = c2 * r2 * (global_best_position[i] - particle['position'][i])           # 粒子对整体最佳位置吸引力

            # 0.8 为惯性权重，控制原有速度保持程度
            particle['velocity'][i] = 0.8 * particle['velocity'][i] + cognitive_component + social_component
            particle['position'][i] += particle['velocity'][i]

            # （可选）确保粒子出现在 （-5, 5）之间
            particle['position'][i] = max(x_left, min(particle['position'][i], x_right))

            
            # 计算新位置的适应度
            current_value = objective_function(particle['position'])
            if current_value < particle['best_value']:
                particle['best_value'] = current_value
                particle['best_position'][i] = particle['position'][i]

# 主算法
def particle_swarm_optimization(objective_function, particle_count=30, max_iterations=100):
    
    dimension = 2
    particles = initialize_particles(particle_count, dimension)

    global_best_value = float('inf')
    global_best_position = None
    
    for i in range(max_iterations):
        for particle in particles:
            current_value = objective_function(particle['position'])
            
            # 更新更优的目标值（函数的最小值）
            if current_value < global_best_value:
                global_best_value = current_value
                global_best_position = particle['position']
                
        update_particles(particles, global_best_position)
        
        # 可以在这里打印每次迭代的全局最佳值
        print(f"Iteration {i+1}, pos{global_best_position}, Best Value: {global_best_value}")
    
    return global_best_position, global_best_value

# 运行PSO算法
best_position, best_value = particle_swarm_optimization(objective_function)
print(f"Best Position: {best_position}, Best Value: {best_value}")
```


绘制图形展示结果：


```python
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# 定义函数
def objective_function(x, y):
    return 3 * np.cos(x * y) + x + y**2

# 创建 x 和 y 的值网格
x = np.linspace(-5, 5, 100)
y = np.linspace(-5, 5, 100)
X, Y = np.meshgrid(x, y)
Z = objective_function(X, Y)

# 绘制图形
fig = plt.figure(figsize=(10,15))
ax = fig.add_subplot(111, projection='3d')
ax.plot_surface(X, Y, Z, cmap='viridis')
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()
```

3d 图形不太能看出来，使用等高线图

```python
import numpy as np
import matplotlib.pyplot as plt

# 定义函数
def objective_function(x, y):
    return 3 * np.cos(x * y) + x + y**2

# 创建 x 和 y 的值网格
x = np.linspace(-5, 5, 1000)
y = np.linspace(-5, 5, 1000)
X, Y = np.meshgrid(x, y)
Z = objective_function(X, Y)

# 绘制等高线图
plt.figure()
cp = plt.contourf(X, Y, Z, cmap='viridis')  # 使用填充等高线图
plt.colorbar(cp)  # 显示颜色条
plt.scatter([-5], [-0.61056878], color='r')  # 在给定点绘制红点

plt.xlabel('X')
plt.ylabel('Y')
plt.title('Contour plot of the function 3*cos(x*y) + x + y^2')
plt.show()
```










----------------

参考资料：
- [七种启发式算法](https://zhuanlan.zhihu.com/p/371637604)
- [scikit-opt 官方文档](https://scikit-opt.github.io/scikit-opt/#/zh/README)
- [粒子群优化算法(Particle Swarm Optimization, PSO)的详细解读](https://zhuanlan.zhihu.com/p/346355572)