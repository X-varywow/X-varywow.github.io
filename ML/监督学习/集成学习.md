
单独一个学习器常常不够完美，有时候也会给我们错误的结果。然而将很多学习器结合起来，就可以超出预期的效果。

集成学习框架：
- Bagging
  - Random Forest, 随机森林
- Boosting
  - AdaBoost
  - GBDT
- Stacking


------------

`Bagging`, Bootstrap aggregating。

每个基学习器基于不同子训练集进行训练，并综合所有基学习器的预测值得到最终的预测结果。

常见的综合方法是投票法

------------

`Boosting` 

训练过程为阶梯状，新的基模型会在前一个基模型的基础上进行学习。

然后综合所有基模型的预测值，常用加权法


------------

`Stacking`

它通过组合多个基础模型的预测结果，以及一个元模型来进行最终的预测。

不同之处：Stacking 不仅仅将基础模型的预测结果作为输入，还将基础模型的预测结果与实际标签一起输入到元模型中进行训练。






--------------------

参考资料：
- [最常用的决策树算法！Random Forest、Adaboost、GBDT 算法](https://mp.weixin.qq.com/s/2pLC58IqSsocRpZls5dmFw) ⭐️
- chatgpt