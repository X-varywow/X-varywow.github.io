
## 1. 读写及特征提取

参考资料：[语音识别中的MFCC 与 Fbank特征的基本原理和python实现](https://zhuanlan.zhihu.com/p/363153781)

```python
import torch
import torchaudio

# 语音读写
waveform, sample_rate = torchaudio.load('demo1.wav')

torchaudio.save('output1.wav', waveform, sample_rate) # 保存wav格式
torchaudio.save('output1.mp3', waveform, sample_rate) # 保存mp3格式
torchaudio.save('output1.flac', waveform, sample_rate) # 保存flac格式
```

```python
# 傅里叶变换

import torchaudio

x, fs = torchaudio.load('demo1.wav')

spec = torchaudio.transforms.Spectrogram(1024,hop_length=160)
#spec = torchaudio.transforms.MelSpectrogram(fs, 1024, n_mels=80)

y = spec(x) # shape[batch=1, channels=513, frames=128]

print('x:', x.shape)  # torch.Size([1, 65328])
print('y:', y.shape)  # torch.Size([1, 513, 409])
print(65328/160)

```

```python
# 多条语音同时傅里叶变换

import torch
import torchaudio

x, fs = torchaudio.load('demo1.wav')
print ('x:', x.shape)

x = torch.cat([x, x], dim=1) # 拼接
print ('x:', x.shape)

spec = torchaudio.transforms.Spectrogram(1024)
y = spec(x) # shape[batch=1, channels=513, frames=128]
print('y:', y.shape)
```

```python
# 画语谱图

import torchaudio
import torchvision

x, fs = torchaudio.load('demo1.wav')
transformer = torchvision.transforms.Resize((160,80))
spec = torchaudio.transforms.Spectrogram(1024)
y = spec(x) # shape[batch=1, channels=513, frames=128]
y_resize = transformer(y)
import matplotlib
import matplotlib.pyplot as plt

fig, axis = plt.subplots(1, 2, figsize=(20,10)) # 创建 图例 和 坐标轴
im = axis[0].imshow(y[0].log().numpy(), aspect="auto", origin="lower") # image show
im = axis[1].imshow(y_resize[0].log().numpy(), aspect="auto", origin="lower") # image show

fig.canvas.draw()
fig.savefig('demo1.png')

plt.close()
```

```python
# 缩放图片大小

import torch
import torchvision

transform = torchvision.transforms.Resize((513, 513))
x = torch.randn(1, 513, 128) # random normal


y = transform(x)

print(x.shape)
print(y.shape)
```


## 2. 深度学习基础

```python
# 线性变换
import torch

B, T, Ci, Co = 2, 200, 80, 10
net = torch.nn.Linear(Ci, Co)

x = torch.randn(B, T, Ci)
y = net(x)

print('x:', x.shape)
print('y:', y.shape)
print(y[0][-1].softmax(-1))
print(y[0][-1].softmax(-1).sum())

# x: torch.Size([2, 200, 80])
# y: torch.Size([2, 200, 10])
# tensor([0.1045, 0.1275, 0.0583, 0.0909, 0.1118, 0.0610, 0.0915, 0.1077, 0.1459,
#         0.1009], grad_fn=<SoftmaxBackward>)
# tensor(1., grad_fn=<SumBackward0>)
```

```python
# 修改数据形状
import torch

x = torch.tensor([[1,2,3],[4,5,6]])
print(x)
print(x.shape) # [2,3]

y = x.reshape(3,2)
print(y)
print(y.shape) # [3,2]

y = x.transpose(0,1)
print(y)
print(y.shape) # [3,2]
```

```python
import torch

x = torch.randn(2, 80, 80)
x = x.reshape(2, 6400)
# x = ....reshape(2,80,80)
net1 = torch.nn.Linear(6400, 128)
y = net1(x)
y = y.sigmoid() # [2, 128]
net2 = torch.nn.Linear(128, 10)
z = net2(y).softmax(-1)
```

## 3. 简单训练模型

```python
import torch

# 随机生成1000组样本
x = torch.randn(1000,5)
w = 1.5
b = 0.2
y_true = w * x + b
"""
[0.5 0.0]  [x1]  + [0.6]  = [0.5 x1 + 0.0 x2 + 0.6] = 0.5 [x1] + 0.6
[0.0 0.5]  [x2]    [0.6]  = [0.0 x1 + 0.5 x2 + 0.6]       [x2]
"""
# 创建一个线性网络 Y=Wx+b
net = torch.nn.Linear(5,5)

# 创建优化器
adam = torch.optim.Adam(net.parameters(), lr=0.01)
#lr是学习率，0.01

print('原始参数','*'*100)
print('W:', net.weight.data)
print('b:', net.bias.data)

# 定义损失，利用优化器求解
for i in range(5000):

    y_pred = net(x)
    loss = (y_true - y_pred).pow(2.0).mean()

    adam.zero_grad() # 所有梯度清零
    loss.backward() # BP算法逆向计算梯度
    adam.step()     # 更新模型参数 θ ← θ - μ m/sqrt(s)

    print('Iter %03d: loss %f'%(i,loss), end='\r')

print('最终参数','*'*100)
print('W:', net.weight.data.argmax())
print('b:', net.bias.data)
```

```python
t = torch.tensor([3,3,3,3,3], dtype = torch.float)

print(net(t))
# -> tensor([4.7001, 4.7000, 4.6998, 4.7000, 4.7000], grad_fn=<AddBackward0>)
```

## 4. 分类模型

```python
# 交叉熵用法
import torch

ce = torch.nn.CrossEntropyLoss()

B, C = 32, 10
predict = torch.randn(B, C)

# 目标是概率值
target = torch.randn(B, C).softmax(-1) # net(x)
loss = ce(predict, target)
print(loss)

# 目标是类别
target = torch.empty(B, dtype=torch.long).random_(C) 
loss = ce(predict, target)
print(target)
print(loss)
```

```python
# 自定义神经网络
import torch

class Network(torch.nn.Module):
    def __init__(self, time=80, freq=80, hidden=512, digits=10):
        super().__init__()
        self.input_dim = time * freq
        self.linear1 = torch.nn.Linear(time*freq, hidden)
        self.linear2 = torch.nn.Linear(hidden, digits)
    def forward(self, x):
        o = x.reshape(-1, self.input_dim)
        o = self.linear1(o).sigmoid()
        o = self.linear2(o).softmax(-1)
        return o

if __name__ == "__main__":

    # 随机生成代表数据（以后请用真实数据）
    B, T, F, C = 32, 80, 80, 10
    x = torch.randn(B, T, F)
    y_true = torch.randint(0,C,(B,))
    # 创建识别网络
    net = Network(T, F, 512, C)
    # 预测
    y_pred = net(x)
    # 计算损失
    ce = torch.nn.CrossEntropyLoss()
    loss = ce(y_pred, y_true)
    print(loss)
```

## 5. 卷积与池化

- 卷积
  - 单通道
  - 多通道
- 池化
  - 最大池化
  - 平均池化


[如何通俗易懂地解释卷积？](https://www.zhihu.com/question/22298352)

>所谓两个函数的卷积，本质上就是先将一个函数翻转，然后进行滑动叠加。


```python
# 二维卷积， Python 实现

import numpy as np

channel_in, channel_out = 3, 64
height, width = 5, 5
kernel_height, kernel_width = 3, 3

x = np.random.randn(channel_in, height, width)
w = np.random.randn(channel_in, channel_out, kernel_height, kernel_width)

y = np.zeros((channel_out, height-kernel_height+1, width-kernel_width+1))

for co in range(channel_out):
    for ci in range(channel_in):
        for i in range(height-kernel_height+1):
            for j in range(width-kernel_width+1):
                weight = w[ci, co]
                data = x[ci, i:i+kernel_height, j:j+kernel_width]
                y[co, i, j] += (weight * data).sum()

print(x)                 
print(y)
```

```python
# 二维卷积， Pytorch 实现

import torch

batch = 1
channel_in, channel_out = 3, 64
height, width = 5, 5
kernel_height, kernel_width = 3, 3

x = torch.randn(batch, channel_in, height, width)
net = torch.nn.Conv2d(channel_in, channel_out, 
                    kernel_size=(kernel_height, kernel_width),
                    bias=False)
y = net(x)

print(x.shape)
print(y.shape)
```

```python
# 一维卷积

import torch

batch = 1
channel_in, channel_out = 3, 64
length = 5
kernel = 3

x = torch.randn(batch, channel_in, length)
net = torch.nn.Conv1d(channel_in, channel_out, 
                    kernel_size=kernel, bias=False)
y = net(x)

print(x.shape)
print(y.shape)
```

```python
# 空洞卷积（2d）

import torch

batch = 1
channel_in, channel_out = 3, 64
height, width = 5, 5
kernel_height, kernel_width = 3, 3

x = torch.randn(batch, channel_in, height, width)
net = torch.nn.Conv2d(channel_in, channel_out, 
                    kernel_size=(kernel_height, kernel_width),
                    bias=False, dilation=2)
y = net(x)

print(x.shape)
print(y.shape)
```

```python
# 卷积步进（2d）

import torch

batch = 1
channel_in, channel_out = 3, 64
height, width = 5, 5
kernel_height, kernel_width = 3, 3

x = torch.randn(batch, channel_in, height, width)
net = torch.nn.Conv2d(channel_in, channel_out, 
                    kernel_size=(kernel_height, kernel_width),
                    bias=False, stride=2)
y = net(x)

print(x.shape)
print(y.shape)
```

利用 padding 来进行卷积填充

## 6. LeNet 网络

https://www.jianshu.com/p/cd73bc979ba9

https://www.ruanx.net/lenet/

## 7. 梅尔谱

总体流程：预加重（提升高频能量，抑制低频能量）、分帧、加窗、傅里叶变换、梅尔滤波、取对数

```python
# 预加重

import numpy as np
import scipy
import scipy.signal

# 计算频率响应
nfft, fs = 512, 16000
w, fr = scipy.signal.freqz([1, -0.95], [1], nfft, whole=True)

# 幅度响应改用dB为单位
db = np.log10(np.abs(fr)**2)*10

for i in range(1,nfft//2+1):
    print('%d: %4.0f %f'%(i, w[i]/(2*np.pi)*fs, db[i]))
```

```python
# 傅里叶变换

import numpy as np
import torchaudio
import matplotlib.pyplot as plt

filename = "/home/yz2018/asr2022/database/201911XXYYZZ_1.wav"
x, fs = torchaudio.load(filename)
x = torchaudio.transforms.Resample(fs, 16000)(x)
x = x.numpy()[0,:]
# x = x[1:]-0.95*x[:-1]
i = x.argmax()
x = x[i-512:i+512]
w = np.hanning(1024)
y = np.log10(np.abs(np.fft.fft(x*w)**2)+1e-5)*10
print(x.shape, w.shape, y.shape)

fig, axis = plt.subplots(2, 1, figsize=(20,10)) # 创建 图例 和 坐标轴
hz = np.arange(1024)*16000.0/1024
im = axis[0].plot(x)
im = axis[1].plot(hz[:513], y[:513])
fig.canvas.draw()
fig.savefig('demo3.png')

plt.close()
```

<img src="https://img-1301102143.cos.ap-beijing.myqcloud.com/20230420220636.png">

## 8. DateSet DataLoader

```python
# DataSet

import os,torch
import torchaudio,torchvision
from torchaudio.transforms import *

class MyData(torch.utils.data.Dataset):
    def __init__(self,dirname):
        super().__init__()
        self.names = sorted(['%s/%s'%(dirname, x) for x in os.listdir(dirname)])
        self.fbank = torchaudio.transforms.Spectrogram(1024)

    def __len__(self):
        return len(self.names)

    def __getitem__(self,index):
        x, fs = torchaudio.load(self.names[index])
        if x.shape[0]>1: x= x[0:1, :]
        if fs != 16000: x=Resample(fs,16000)(x)
        x = torchvision.transforms.Resize((80,80))(self.fbank(x))
        y = int(self.names[index][-5])
        return x,y

if __name__== '__main__':
    data = MyData('/home/yz2018/asr2022/database')
    print(len(data),data.__getitem__(0)[0].shape)
    print(len(data),data.__getitem__(0)[1])
```

```python
# Model

import torch

class Network(torch.nn.Module):
    def __init__(self,time=80,freq=80,hidden=512,digits=10):
        super().__init__()
        self.input_dim = time * freq
        self.linear1 = torch.nn.Linear(time*freq,hidden)
        self.linear2 = torch.nn.Linear(hidden,digits)

    def forward(self, x):
        o = x.reshape(-1,self.input_dim)
        o = self.linear1(o).sigmoid()
        o = self.linear2(o)
        return o

if __name__=='__main__':
    net = Network()
    x = torch.randn(4,80,80)
    y=net(x)
    print(x.shape,y.shape)
```

```python
# DataLoader

import torch
from model import Network
from dataset import MyData
from torch.utils.data.dataloader import DataLoader

def train (dirname):
    net = Network()
    adam = torch.optim.Adam(net.parameters(),lr = 1e-2)
    dataset= MyData(dirname)
    dataloader= DataLoader(dataset,batch_size=16, num_workers=4,shuffle=True)
    for epo in range(100):
        for i,(x,y) in enumerate(dataloader):
            y_pred= net(x)
            loss = torch.nn.CrossEntropyLoss()(y_pred,y)
            adam.zero_grad()
            loss.backward()
            adam.step()
            error = (y != y_pred.argmax(-1)).sum()
            print("epo %03d step %03d: loss %.4f"%(epo, i, loss.cpu().item()),error, y, y_pred.argmax(-1),)

if __name__=='__main__':
    train('/home/yz2018/asr2022/database')
```










