
论文地址：https://arxiv.org/abs/2304.09116

模型介绍：https://www.msra.cn/zh-cn/news/features/naturalspeech-2


微软 2023.5 研究的比 VALL-E 还要好些的模型

NaturalSpeech 2 首先利用神经语音编解码器（Neural Audio Codec，如图2所示）的编码器（encoder），将语音波形转换为连续向量并用解码器（decoder）重建语音波形，再运用潜在扩散模型（Latent Diffusion Model）以非自回归的方式从文本预测连续向量。在推理时，利用潜在扩散模型和神经语音解码器从文本生成语音的波形。


1. 使用连续向量替代离散 token。离散 token 会导致序列长度过长（例如，使用8个残差向量量化器，序列长度会增加8倍），增加了预测的难度。而连续向量可以缩短序列长度，同时增加细粒度重建语音所需要的细节信息。

2. 采用扩散模型替代自回归语言模型。通过非自回归的生成方式，能避免自回归模型中的错误累积所导致的韵律不稳定、重复吐次漏词等问题。

3. 引入语音提示机制，激发上下文学习能力。研究员们创新设计的语音提示机制（如图3所示），让扩散模型和时长/音高预测模块能够更高效地学习语音上下文，从而提升了零样本的预测能力。


## 测试

听音质：https://speechresearch.github.io/naturalspeech2/

音色，声音听起来，有时忽大忽小，瑕疵挺多（比 AI syz）
