
## _preface_

æ”¯æŒå…¨æ–¹ä½çš„è§†è§‰ AI ä»»åŠ¡ï¼ŒåŒ…æ‹¬ç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€å›¾åƒåˆ†ç±»ã€å§¿åŠ¿ä¼°è®¡ã€è·Ÿè¸ª


> ï¼ˆè‡ªç”¨ï¼‰ä¸»è¦ä»»åŠ¡ï¼šæ¸¸æˆä¸­,æ£€æµ‹æ€ªç‰©å’Œæ‰è½ç‰©ï¼Œç”¨äºåç»­ç”¨é€”ï¼›åç»­â€œæœ¬ä»»åŠ¡â€éƒ½æŒ‡è¿™ä¸ª




å‚è€ƒï¼š[å®˜æ–¹ colab tutorial](https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb) â­ï¸





```python
%pip install ultralytics
import ultralytics
ultralytics.checks()
```

```python
!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/zidane.jpg'
```



```python
from ultralytics import YOLO

# Create a new YOLO model from scratch
model = YOLO("yolov8n.yaml")

# Load a pretrained YOLO model (recommended for training)
model = YOLO("yolov8n.pt")

# Train the model using the 'coco8.yaml' dataset for 3 epochs
results = model.train(data="coco8.yaml", epochs=3)

# Evaluate the model's performance on the validation set
results = model.val()

# Perform object detection on an image using the model
results = model("https://ultralytics.com/images/bus.jpg")

# Export the model to ONNX format
success = model.export(format="onnx")
```





</br>

## _æµç¨‹_


### æ ¼å¼å®šä¹‰

https://docs.ultralytics.com/datasets/detect/


```python
# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: ../datasets/coco8 # dataset root dir (absolute or relative; if relative, it's relative to default datasets_dir)
train: images/train # train images (relative to 'path') 4 images
val: images/val # val images (relative to 'path') 4 images
# test: # test images (optional)

# Classes (80 COCO classes)
# å®šä¹‰ label, æ£€æµ‹ç›®æ ‡
names:
    0: person
    1: bicycle
    2: car
    # ...
    77: teddy bear
    78: hair drier
    79: toothbrush
```


æ ‡æ³¨å·¥å…·ï¼š[LabelImg](https://github.com/HumanSignal/labelImg), æœ€åä½¿ç”¨äº† [label studio](https://labelstud.io/guide/quick_start)


æ ‡æ³¨å¥½äº†ä¹‹åæŒ‰ç…§ yolo æ ¼å¼å¯¼å‡ºï¼Œç„¶åè‡ªå·±æ–°å»ºä¸€ä¸ª data.yaml å³å¯ï¼Œæ³¨æ„ç¼–å·ä¸æ ‡æ³¨æ—¶å¯¹åº”ã€‚





### è®­ç»ƒ

https://docs.ultralytics.com/modes/train


```python
!yolo train model=yolo11n.pt data=coco8.yaml epochs=3 imgsz=640
```

å‘½ä»¤è¡Œæ–¹å¼æ¯”è¾ƒä¾¿æ·ï¼Œæ ‡æ³¨å¥½æ•°æ®ï¼Œå®šä¹‰å¥½ æ•°æ®æè¿°æ–‡ä»¶ `.yaml` å°±å·®ä¸å¤šå¯ä»¥è®­ç»ƒäº†ï¼› `n` è¡¨ç¤º nano, æœ€å°çš„ã€‚


-------------

```python
from ultralytics import YOLO

# Load a model
model = YOLO('yolo11n.yaml')  # build a new model from scratch
model = YOLO('yolo11n.pt')  # load a pretrained model (recommended for training)

# Use the model
results = model.train(data='coco8.yaml', epochs=10)  # train the model
results = model.val()  # evaluate model performance on the validation set
results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image
results = model.export(format='onnx')  # export the model to ONNX format
```

é»˜è®¤ imgsz=640ï¼Œ ä¼šæŠŠå›¾ç‰‡ç¼©æ”¾ç»Ÿä¸€å¤§å°ï¼Œ(ä¿æŒé•¿å®½æ¯”ï¼Œå¢åŠ é»‘è¾¹)


--------------

export ç›¸å…³ï¼Œ

ğŸ’¡ ProTip: Export to ONNX or OpenVINO for up to 3x CPU speedup.

ğŸ’¡ ProTip: Export to TensorRT for up to 5x GPU speedup.




--------------



1. detection

```python
from ultralytics import YOLO

model = YOLO('yolo11n.pt')  # load a pretrained YOLO detection model
model.train(data='coco8.yaml', epochs=3)  # train the model
model('https://ultralytics.com/images/bus.jpg')  # predict on an image
```

2. segmentation

```python
from ultralytics import YOLO

model = YOLO('yolo11n-seg.pt')  # load a pretrained YOLO segmentation model
model.train(data='coco8-seg.yaml', epochs=3)  # train the model
model('https://ultralytics.com/images/bus.jpg')  # predict on an image
```

3. classification

```python
from ultralytics import YOLO

model = YOLO('yolo11n-cls.pt')  # load a pretrained YOLO classification model
model.train(data='mnist160', epochs=3)  # train the model
model('https://ultralytics.com/images/bus.jpg')  # predict on an image
```




### æ¨ç†


half åŠç²¾åº¦æ¨ç†ï¼ˆfloat16ï¼‰

```python
model.predict(source='your_test_images/', half=True)
```

---------------

å‘½ä»¤è¡Œæ–¹å¼

```python
# Run inference on an image with YOLO11n
!yolo predict model=yolo11n.pt source='https://ultralytics.com/images/zidane.jpg'
```






### éªŒè¯

https://docs.ultralytics.com/modes/val

```python
# Download COCO val
import torch
torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)
!unzip -q tmp.zip -d datasets && rm tmp.zip  # unzip
```

```python
!yolo val model=yolo11n.pt data=coco8.yaml
```

yolo11n.pt  6 mb...


----------------

æŒ‡æ ‡ä»‹ç»ï¼š

```
YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs
                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.10s/it]
                   all          4         17      0.583       0.85      0.849       0.65
                person          3         10        0.6        0.6      0.591       0.28
                   dog          1          1      0.549          1      0.995      0.796
                 horse          1          2      0.552          1      0.995      0.674
              elephant          1          2      0.369        0.5      0.525       0.26
              umbrella          1          1      0.573          1      0.995      0.995
          potted plant          1          1      0.857          1      0.995      0.895
```

- Box(p), å‡†ç¡®ç‡ $\frac{TP}{TP+FP}$ï¼Œè¾¹ç•Œæ¡†ä¸­å¹³å‡ 58.3% æ˜¯åˆ¤æ–­å‡†ç¡®çš„æ­£ä¾‹ï¼›å¯èƒ½åŸå› ï¼šæ ·æœ¬å°‘ã€é®æŒ¡ç­‰
- Box(r), å¬å›ç‡ $\frac{TP}{TP+FN}$ï¼Œæ£€æµ‹å‡ºäº† 85% çš„çœŸå®ç›®æ ‡
- mAP50, IoUé˜ˆå€¼ä¸º0.5æ—¶çš„å¹³å‡ç²¾åº¦
- mAP50-95, IoUé˜ˆå€¼ä»0.5åˆ°0.95çš„å¹³å‡ç²¾åº¦


`IoU`, Intersection over Union, äº¤å¹¶æ¯”; ç”¨äºè¡¡é‡é¢„æµ‹è¾¹ç•Œæ¡†ä¸çœŸå®è¾¹ç•Œæ¡†é‡å ç¨‹åº¦çš„æŒ‡æ ‡ã€‚

$$IoU = \frac{Area\ of\ Overlap}{Area\ of\ Union} = \frac{é¢„æµ‹æ¡† \cap çœŸå®æ¡†}{é¢„æµ‹æ¡† \cup çœŸå®æ¡†}$$

é€šå¸¸è®¤ä¸º IoU >= 0.5 æ—¶æ£€æµ‹æœ‰æ•ˆï¼›

`mPA`, mean Average Precision. æ‰€æœ‰ç±»å‹APï¼ˆç­‰åŒPR æ›²çº¿ä¸‹çš„é¢ç§¯ï¼‰çš„å¹³å‡å€¼

æœ¬ä»»åŠ¡ä¸­ï¼Œå…³æ³¨ mAP50, å¯¹è¾¹ç•Œæ¡†åªéœ€è¦å¤§è‡´å®šä½å³å¯ï¼Œæ‰è½ç‰©ã€æ€ªç‰©ç­‰...






## _other_


### ç›®æ ‡è·Ÿè¸ª

https://docs.ultralytics.com/modes/track

```python
import cv2

from ultralytics import YOLO

# Load the YOLO11 model
model = YOLO("yolo11n.pt")

# Open the video file
video_path = "path/to/video.mp4"
cap = cv2.VideoCapture(video_path)

# Loop through the video frames
while cap.isOpened():
    # Read a frame from the video
    success, frame = cap.read()

    if success:
        # Run YOLO11 tracking on the frame, persisting tracks between frames
        results = model.track(frame, persist=True)

        # Visualize the results on the frame
        annotated_frame = results[0].plot()

        # Display the annotated frame
        cv2.imshow("YOLO11 Tracking", annotated_frame)

        # Break the loop if 'q' is pressed
        if cv2.waitKey(1) & 0xFF == ord("q"):
            break
    else:
        # Break the loop if the end of the video is reached
        break

# Release the video capture object and close the display window
cap.release()
cv2.destroyAllWindows()
```


### åŸç†

å°†ç›®æ ‡æ£€æµ‹è§†ä¸ºå›å½’é—®é¢˜ï¼Œå°†å›¾åƒåˆ’åˆ†ä¸ºåŒºåŸŸï¼Œå¹¶é¢„æµ‹æ¯ä¸ªåŒºåŸŸçš„è¾¹ç•Œæ¡†å’Œç±»åˆ«æ¦‚ç‡







--------------


explorer, ä¸ llm ç»“åˆä¸€èµ·äº†

https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/docs/en/datasets/explorer/explorer.ipynb


