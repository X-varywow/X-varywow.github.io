
<img src="https://img-1301102143.cos.ap-beijing.myqcloud.com/20230726213625.png">

## 1. Python

Numpy 具有 **广播** 功能，不同形状数组也可运算

```python
import numpy as np

A = np.array([1,2],[3,4])
B = np.array([10, 20])

A*B    # -> [[10, 40],[30, 80]]
```

访问元素

```python
X = np.array([[51, 55], [14, 19], [0, 4]])

X[0]

X[0][1]

X = X.flatten() # [51, 55, 14, 19, 0, 4]

X[np.array[0, 2]] # [51, 14]

X > 15 # array([True, True, False ... ], dtype = bool)

X[X>15] # array([51, 55, 19])

np.all(X == 51) # False
```

------------

matplotlib 还具有读取&显示图像的功能

书中例子：
```python
import matplotlib.pyplot as plt
from matplotlib.image import imread

img = imread("demo.png")
plt.imshow(img)

plt.show()
```

在图上绘制散点（人脸关键点检测会用到）(直接 scatter 就行)：

```python
import matplotlib.pyplot as plt

x, y = [i[0] for i in points], [i[1] for i in points]

im = plt.imread("person_head.png")
plt.imshow(im)
plt.scatter(x, y,  c='b', s=10)

plt.show()
```



## 2. 感知机

感知机，就是多个输入、设定权重和阈值，用来判断“神经元是否激活”


```python
def AND(x1, x2):
    w1, w2, theta = 0.5, 0.5, 0.7
    tmp = x1*w1 + x2*w2
    if tmp <= theta:
        return 0
    elif tmp > theta:
        return 1
```


```python
def AND(x1, x2):
    x = np.array([x1, x2])
    w = np.array([0.5, 0.5])
    b = -0.7
    tmp = np.sum(w*x) + b
    if tmp <= 0:
        return 0
    else:
        return 1
```

单层感知机无法表示异或门，利用多层感知机实现。

感知机通过叠加层能够进行非线性表示。

```python
def XOR(x1, x2):
    s1 = NAND(x1, x2)
    s2 = OR(x1, x2)
    y = AND(s1, s2)
    return y
```
**感知机是神经网络的基础。**

## 3. 神经网络

神经网络，能够 **自动地从数据中学习到合适的权重参数**。

一个典型的二层神经网络（只有2层神经元有权重）：

<img src="https://img-1301102143.cos.ap-beijing.myqcloud.com/20230726212411.png" style="zoom:60%">

- 输入层
- 中间层（隐藏层）
- 输出层




激活函数(待补充)

回归问题用恒等函数，分类问题用 softmax 函数

P66 softmax 运算中容易越界，改进

```python
def softmax(a):
    c = np.max(a)
    exp_a = np.exp(a - c) # 溢出对策
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a
    return y
```

softmax 输出值总和为 1




简单定义3层神经网络：

```python
def init_network():
    network = {}
    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])
    network['b1'] = np.array([0.1, 0.2, 0.3])
    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])
    network['b2'] = np.array([0.1, 0.2])
    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])
    network['b3'] = np.array([0.1, 0.2])
 return network

def forward(network, x):
    W1, W2, W3 = network['W1'], network['W2'], network['W3']
    b1, b2, b3 = network['b1'], network['b2'], network['b3']
    a1 = np.dot(x, W1) + b1
    z1 = sigmoid(a1)
    a2 = np.dot(z1, W2) + b2
    z2 = sigmoid(a2)
    a3 = np.dot(z2, W3) + b3
    y = identity_function(a3)
    return y

network = init_network()
x = np.array([1.0, 0.5])
y = forward(network, x)
print(y) # [ 0.31682708 0.69627909]
```

P62.jpg

p74 手写数字识别，输入层784（图像大小28\*28），输出层10\* (10个类别)

都是矩阵，且可以打包式输入数据（批 batch）

?> 数据传送称为瓶颈时，批处理可以减轻数据总线的负荷


```python
x, t = get_data()
network = init_network()
batch_size = 100 # 批数量
accuracy_cnt = 0
for i in range(0, len(x), batch_size):
    x_batch = x[i:i+batch_size]
    y_batch = predict(network, x_batch)
    p = np.argmax(y_batch, axis=1)
    accuracy_cnt += np.sum(p == t[i:i+batch_size])
print("Accuracy:" + str(float(accuracy_cnt) / len(x)))
```

小结：介绍了神经网络基本概念、激活函数、批处理



## 4. 神经网络的学习

“学习” ： 从训练数据中自动获取最优权重参数的过程。

在与门的感知机中，参数只有3个。在具有成千上万个参数的神经网络中，自动设置参数意义重大。

数据驱动，😭，数据是机器学习的核心，从数据中发现模式


------

demo：识别 5 的算法

旧方案：从图像中提取特征量（数学方法，SIFT, SURF, ORB等） + 机器学习分类器（SVM, KNN）

缺点：必须人为设计专门的特征量，不够高效

</br>

神经网络方法（学习过程中不存在人为介入），高效

当深度学习可以直接输入原始数据，获得目标结果时，常称为端到端机器学习。

------------

mini-batch 学习：从训练数据中选择部分批量数据进行学习

基本概念

------------

### 4.3 & 4.4 微分&梯度

在进行神经网络的学习时，不能将识别精度作为指标。因为如果以识别精度为指标，则参数的导数在绝大多数地方都会变为0。P93

```python
# 不好的实现示例
def numerical_diff(f, x):
    h = 10e-50
    return (f(x+h) - f(x)) / h

np.float32(1e-50) # 0.0 计算机无法表示这个数

# 优化1 改变微小值
# 优化2 中心差分替代前向差分
def numerical_diff(f, x):
    h = 1e-4 # 0.0001
    return (f(x+h) - f(x-h)) / (2*h)
```


导数、偏导(某地方变化方向)、梯度（偏导构成的向量）

负梯度方向是梯度法中变量的更新方向。

梯度指示的方向是各点处函数值最小最多的方向。

P102






## 5. 误差反向传播

## 6. 与学习相关的技巧

## 7. 卷积神经网络

## 8. 深度学习
















适合初学者，容易入门，建立整个深度学习的框架








阅读进度：P82